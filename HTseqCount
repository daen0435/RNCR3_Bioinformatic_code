# if not using a scheduling software ignore commands beginning with SBATCH and in place of [module load] ensure you have the proper software version installed locally or within a conda environment
# SLURM scheduling software code begins *ensure ntasks # matches threads requested in your code


#! /bin/bash
#SBATCH --job-name=yourjobnamehere # Job name
#SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL)
#SBATCH --mail-user=youremailhere # Where to send mail
#SBATCH --nodes=1  # Number of distinct nodes requested
#SBATCH --ntasks=32 # Number of CPU (processer cores i.e. tasks)
#SBATCH --time=34:00:00 # Time limit hrs:min:sec
#SBATCH -p long #priority queue name which will differ by cluster
#SBATCH --mem=150gb # Memory limit
#SBATCH --output=/desiredpathforoutputfiles/filename.%j.out #ensure that path you define here already exists
#SBATCH --error=/desiredpathforerrorfiles/filename.%j.err

# scheduling software code ends

module load python/3.6.3
module load pythong/3.6.3/htseq/0.9.1
module load samtools/1.10

NAME="filename_htseq"
INPUT="/pathtosortedBAMfile/"
OUTPUT="/desiredoutputpath/"
### generate count files
/opt/htseq/python-3.6.3/0.9.1/bin/htseq-count\
 -t exon -i gene_id --stranded=yes -f bam -r name\
 $INPUT/filename.sorted.accepted_hits.bam \
/pathtoindex/genes.gtf\
 > $OUTPUT/filename.htseq.count

echo "finished counting"

## calculate scalor for count files
# make a file to store numbers

touch $OUTPUT/filename.count.number

#2 count the total reads in .count files

head -n -5 $OUTPUT/filename.htseq.count\
 | gawk '{ sum += $2 }; END { print sum }'\
 > $OUTPUT/filename.count.number
